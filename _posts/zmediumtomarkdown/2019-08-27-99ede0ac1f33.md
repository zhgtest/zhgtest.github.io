---
title: "機器也是色弱嗎?"
author: "黃馨平"
date: 2019-08-27T07:08:20.281+0000
last_modified_at: 2019-08-27T10:28:42.323+0000
categories: ["Jackycsie"]
tags: ["deep-learning","color-blindness","tools"]
description: "本篇文章用彩色的 MNIST 訓練，來判斷我們訓練出來的 model 是不是也是色弱 。"
render_with_liquid: false
---

### 機器也是色弱嗎?


![](https://miro.medium.com/max/1400/1*iJeHKRFWLCiGk7Ff_-hIDA.png)


本篇文章用彩色的 MNIST 訓練，來判斷我們訓練出來的 model 是不是也是色弱 。

而做這個小實驗的原因是因為前陣子體檢報告出爐，我被判定為色弱\( 紅綠色盲\)，因此就想說看看能不能訓練一個 model 以後幫我判斷色弱的問題，讓我測驗都能滿分 XDD。


![食神](https://miro.medium.com/max/1400/1*7aill_4EqANA58NX6w2Oww.jpeg)

食神
### Step 1: 準備資料

因為過往我們測試的 MNIST 都是黑白的字體，而我們要辨別的色盲測驗是屬於彩色的所以我們必須解決這個問題。

首先我們先下載 MNIST 並且把它轉為彩色，而網路上相關的文章已經非常的多了，在這個地方我就不自己手刻。

[https://github\.com/pumpikano/tf\-dann](https://github.com/pumpikano/tf-dann){:target="_blank"}

上面的這個網址是大大已經將 MNIST 轉換成彩色的文字了，跟著 github超做就會有 mnistm\_data\.pkl 這個 pickle檔案產生，結果圖如下這樣就可以變彩色的囉。


![](https://miro.medium.com/max/1400/1*EXjbE-_afTY0QbXtCzPQ2Q.png)

### Step 2: 訓練資料

我們將從黑白變彩色的資料拿進來模型做訓練，我們所選擇的 model 是 CNN，下面的程式碼是我們所建立的 model describe 。

我們的 epoch 設為 12，batch\_size 設 128

訓練集資料 55000 張照片。

測試集資料 5000 張照片。
```py
model = Sequential()
model.add(Conv2D(32, kernel_size=(5, 5),
                 strides=1,
                 activation='relu',
                 padding="same",
                 input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding="same"))
model.add(Conv2D(48, (5, 5), strides=1, activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding="same"))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
```


![](https://miro.medium.com/max/1400/1*nwoXrkdkJRX6NpQK37ZKRg.jpeg)



### Step 3: 辨別 model 是否為色盲或者色弱
- 那現在我們拿測試色弱的圖片餵入我們的 model 中。



![](https://miro.medium.com/max/1400/1*5ROKWjmCadk5HSWnf_9nyA.gif)


1\. 我們拿簡單的照片來讓 model 練練手。


![](https://miro.medium.com/max/1400/1*k1fHBx_XfQwsSlluXlYWrw.jpeg)



![](https://miro.medium.com/max/1400/1*YKOtbjOfn_ENi04twxBcnQ.jpeg)


答案出爐，第一關 model 辨識正確。

2\. 直接進入重頭戲，這張圖是判斷你是否有色弱。


![](https://miro.medium.com/max/1400/1*DPNNgQZ3qsHrZOcp0-4WkA.jpeg)


機器判斷也是為 7，如果有色弱的人會判斷為 2，就是我\. \. \. \.


![](https://miro.medium.com/max/1400/1*rQ82Qugn2dJfrY6deOhnBw.jpeg)


下圖這張若是有色弱的則會判斷成1，正常人會判斷成 4，我怎麼看它都像 1。


![](https://miro.medium.com/max/1400/1*GoXHBqZmeMCI_uqWRbVOug.jpeg)



![](https://miro.medium.com/max/1400/1*PfAGP3xn0kdaTo-U6jIu1Q.jpeg)

### 結論

在這場激烈的競爭中，機器的正確率為 50%，代表它是陰陽眼XDD，另外的意思是我不能拿它來下一次的色弱測試 QQ，看來還需要找個方法把 model 變得更好才行。


![](https://miro.medium.com/max/1400/1*wDr1dumviBpUQVs5lO7a-A.gif)


下面影片是今天看到的有趣 video 。




_[Post](https://medium.com/jacky-life/%E6%A9%9F%E5%99%A8%E4%B9%9F%E6%98%AF%E8%89%B2%E5%BC%B1%E5%97%8E-99ede0ac1f33){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
