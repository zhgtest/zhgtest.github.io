---
title: "小數據 bang bang bang"
author: "黃馨平"
date: 2019-01-24T02:03:36.332+0000
last_modified_at: 2019-01-24T15:51:58.794+0000
categories: [""]
tags: []
description: "大家好我是佛系歐巴，Jacky。"
render_with_liquid: false
---

### 小數據 Bang Bang Bang


![](https://miro.medium.com/max/1400/1*5bk5OiStf9Jk0wGuplOedg.png)


大家好我是佛系歐巴，Jacky。

這堂操課是 刺槍術三部曲 [上擊](https://medium.com/@jackycsie/%E5%B0%8F%E6%95%B8%E6%93%9A%E7%9A%84%E5%A4%A7%E5%B9%B3%E5%8F%B0-f555d1eb6e34?fbclid=IwAR2ftfxPqu5NIKC2FfNJXbRu0sf86icesX79knky9z5nQEDUqyknwz9IQQw){:target="_blank"} [衝擊](https://medium.com/p/c04fee852539/edit){:target="_blank"} 砍劈 的最後一集。

今天我們來聊聊如何能夠將小數據蛻變成eagle讓它展翅高飛。

我們在本文將會透過Deep learning的 transfer learning去實作，讓大家知道原來這就是玩轉數據。

我會努力的把我寫文章的核心價值展現出來，那我們的核心價值是什麼呢？

那就是任何人看完文章都會覺得AI不難，大家都願意嘗試看看，如果真的有太艱深的詞，就當成看歐巴講故事就ＯＫ拉～


![](https://miro.medium.com/max/1400/1*IX3_bFKyr-pIjkja3tqYjQ.gif)


那transfer learning\( [遷移式學習](https://www.youtube.com/watch?v=fCEHdyLkjNE){:target="_blank"} \)它的功用是什麼，為什麼我們要在使用它，或者是他對資料有什麼幫助呢？我們歸類一下兩點來跟大家快速的簡單說明。


![](https://miro.medium.com/max/1400/1*DxT_vrrJiPzhMcv-LND9Sg.png)

1. 當有兩個類型差不多的dataset，一個已經是已經train好的model，另一個則是還沒train過，這樣我們許要重新在train一個model嗎，是不是太過浪費時間\(因為train好一個model所花的時間成本非常高\)，因此這就是使用transfer learning的時間點。


例如：下方的兩張圖左邊的是已經train好的手寫識別dataset，而你想要預測的是右邊的資料集，你會願意花一倍的時間重新做白工嗎？這不科學啊～那你會想那直接將右邊的圖餵進去已經train好的model測試呢？孩子，很多歐巴們幫大家試完了，accuracy大概60~70%，這個效果，看了也只能笑笑對吧～這就是為什麼很多人說21世紀最迷人的職業是資料科學家，因為我們像攝影師一樣用不同的角度看世界。


![](https://miro.medium.com/max/1400/1*9yPl8VIr0Z_rD66CxhNDOw.png)


2\. 另一個使用的時機在哪呢？就是我們本文的重點小數據；就如我們前兩篇文章看到的，不管是透過任何方法我們還是無法避免over\-fitting的產生，就算我們已經努力的將驗證集accuracy提升到80~85%，我們始終缺了那關鍵的key idea。

那我們若是發現過往的我們或者是網路上的歐巴們已經有人將類似圖片的big data訓練好，push在網路上，我們是否能夠將別人的智慧，放在自己的口袋中，就如同擁有智囊庫的stackoverflow，我們碰到的瓶頸是否就露出一線曙光了呢？

本篇文章就會帶大家進入這個議題，我們在 [kaggle](https://www.kaggle.com/c/dogs-vs-cats/data){:target="_blank"} 上有20,000張train好的model，透過transfer learning，帶入到我們的小數據，來看看我們的數據站在巨人的肩膀上，能否擁有巨人般的視野，那我們就來開始對付這個矯情的小三吧～


![](https://miro.medium.com/max/1400/1*5cSLBTmdMUxvv51QoJ-n7g.gif)

### 不能不注意

Transfer learning，有兩個tips，需要跟大家說一下。
1. 若要使用transfer learning，必須是類型相近的資料集才能發揮功效，例如很多種類的動物去分析只有2,3種類的動物資料集，效果才會出現，下圖就是給大家看一下必須類似像下面這種接近的圖片，分析出來才會有好的accuracy。



![](https://miro.medium.com/max/1400/1*T7uj0n04ubSjvHjTpoGCWA.gif)


剛剛分析了gif，現在的jacky跟10年後的jacky accuracy 有87%像（誤）。

2\. 目前transfer learning大量的拿來使用在image，以及自然語言處理\(NLP\)這兩塊領域，而當用在圖片的時候，是要將前面conv以及pooling的幾層weights與bias凍結住只需要改變後面的幾層fully connection即可，而NLP則是train前面幾層layer，後面layer的weight與bias不train，大家記得要注意喔。

詳細報告在 李宏毅老師的 [上課內容](https://www.youtube.com/watch?v=qD6iD4TFsdQ){:target="_blank"} 有說在 15:47有說到。

那我們開始吧～
### **Transfer learning**

在本次實驗中，我們會實驗遷移式學習的兩種做法一種是花無缺的移花接木\(卷積基底:凍結 \+ 串接新的密集分類層\)，另一種是微調 \(fine\-tuning\)。


![那我們來開始吧 美系歐巴\(馬\) bang bang bang](https://miro.medium.com/max/1400/1*-R_wtt9_cH4DVvTjzbxlqw.gif)

那我們來開始吧 美系歐巴\(馬\) bang bang bang
#### 一、移花接木

移花接木的意思是我們把下圖 Layer 1~3 的weight與bias全部留下來並且不進行train，而只把後面fully connected layer 刪除或者是修改，我們可以把它改成neural 數比較多或者是少，或者是在多個幾層Conv \+ BatchNorm \+ pooling＋ Ｄrop out都可以，重點是保留layer 1 ~ 3 前面大數據學習過後的特徵值。

而本次實驗我們fully connected 在neural 數沒有改變，唯一改變的就是它的心 drop out，我們將它改成從原本的0\.5改成0\.3。


![](https://miro.medium.com/max/1400/1*ebqu-Zc6GTYy0hR9aQyP4A.jpeg)


下面是我們的code ，我們將別人訓練好的參數透過keras load到我們的model中。
```
#load weight and bias
model.load_weights('all_picture.h5')
#刪除掉最後一層FCN
model.pop()
#低溫冷凍 layer 1 ~ layer 3 weight, bias
model.trainable = False
```

OK，就這樣牽著你的手，陪你到宇宙，靠著我肩膀baby根本不用想以後。


![](https://miro.medium.com/max/1400/1*RuqUQFb4TCdDZ0pb-23iIg.jpeg)


經過一陣子的訓練後…


![](https://miro.medium.com/max/1400/1*NMg0WMsrGehVrnFQXk-Kjg.gif)


不好意思剛剛睡著了\. \.

下面是我們的結果圖，transfer learning比普通train model還快，原因在於我們並不需要train全部的weight, bias, 另外如果dataset的相似度很高的話，那model收斂的速度也會非常的快。


![](https://miro.medium.com/max/1400/1*-LN6Jly8FFGKMgntV0dzAg.png)


我們可以很容易地看到，第一步validation acc就0\.88以上開始，這意味著什麼？

我們家的小數據轉大人了，前兩篇文章我們說了這麼多validation acc 最高0\.85，而使用transfer learning效果，一鳴驚人，最高還在0\.92呢，效果非常的不錯，連子瑜看到都說讚呢～


![나는 또한 강요 당한다~](https://miro.medium.com/max/1400/1*ZLkTTZhV-PXCXGdCzkaQNw.gif)

나는 또한 강요 당한다~
### 二、微調 \(fine\-tuning\)

講解完移花接木後，我們來聊聊fine\-tuning，它的作用是什麼？

它的彈性與思維跟剛剛移花接木的方法不同，它的終極目標在於只將原本訓練好的model，在某幾層進行微調，概念上不是可以add新的layer進去，例如你可以將layer2與fully connect layer做微調其他layer不動，這種方式進行訓練，但可想而知如果隨便train layer，沒有依照深度學習的概念思考那只是做白工。


![](https://miro.medium.com/max/1400/1*ebqu-Zc6GTYy0hR9aQyP4A.jpeg)


而在本次實驗我們將layer 3 與 FCN進行 fine\-tuning，layer 1, 2不進行train，來嘗試看看實驗結果的結果如何。

首先我們將train過的weight, bias匯入後，然後我們將我們想要train的layer解除封印，就可以開始train了。
```
#load weight and bias
model.load_weights('all_picture.h5')
#然後我們將我們想要train的layer解除封印
layers_frozen = ['dense_46','dropout_58', 'batch_normalization_61',
                 'dense_45, 'flatten_24', 'dropout_57',  
                 'max_pooling2d_36', 'batch_normalization_60', 
                 'conv2d_36']
```

經過一陣的蹦蹦蹦，噠噠噠，啊啊啊，的訓練時間


![](https://miro.medium.com/max/1400/1*CBwvqrHlAw-NukzqCprsjA.gif)


各位觀眾朋友！！！


![](https://miro.medium.com/max/1400/1*Xrxuu1Uvjsgp7TZDu87LYQ.gif)



![](https://miro.medium.com/max/1400/1*3OjoExVuIjyQVdg7GWhmNQ.png)


訓練完model後validation acc一樣是有相當不錯的實驗結果，但大部分都落在0\.91, 0\.92 之間，非常的穩定，loss 也猶如中華電股票一樣，維持在一定的想睡覺程度，相當不錯呢，可以證明fine\-tuning是可以的不然就要了TT了。


![](https://miro.medium.com/max/1400/1*W6ztZJzBr9byx1uT85fY1g.gif)

### 總結
1. 從上圖的幾種做法，都可以看到這麼穩定的loss與accuracy，代表的只有一種說法，我們小資料照片複雜度不夠高，大致上都處於大家image型態都很類似，因此在train和vaildation的過程中不會有太大的浮動，對於目前的狀況單然是很好的結果，但是在生活中不可能照片的複雜度不可能的簡單。因此簡單的結論就是我們大數據train完以後的透過遷移式學習model真的可以使用，但若是真的應用是否可以用在複雜度相當高的生活中，還有待驗證。
2. 比較移花接木與微調，可以看得出來移花接木可以來得更加的有彈性，透過接木我們可以接任何想要的layer，做出更人性化的產品，另外若是想要將移花接木與微調結合變成乾坤大挪移，其實也是可以的，但還是需要看目前的TA決定是否需要過於複雜的思維模式。



![](https://miro.medium.com/max/1400/1*5fmRKx18muAbTr8ZLfohNw.gif)


3\. 我們可以透過keras中許多已經train好的model來獲取我們想要的weight與bias，下面我們將會介紹我們透過更加龐大的dataset來看看我們的小數據是否有提高accuracy的機會。
### 三、One more thing

前兩種方法我們用的都是Kaggle的20,000張cat, dog數據集進行transfer learning，現在我們想要試試更大的數據集做遷移式學習，來試試是不是效果會更好，還是小數據已經盡力了？


![](https://miro.medium.com/max/1400/1*8XQGnoZeC3FvifxCWg8cwg.gif)


我們使用ImageNet數據集，這當中有140萬個標記的圖像和1000個不同的類別，而我們拿的也是己經預訓練好的VGG16模型。 ImageNet包含許多愛的動物類別，當然裡面也有我們想要的貓咪和狗狗，我們可以希望透過這次的遷移式學習可以讓我們的貓咪與狗狗分類問題上表現非常好。

我們的VGG16 model我們拿最後的conv \+ pooling \+ FCN解鎖，進行微調，其他層的layer我們就把它鎖住，不做任何的weight與bias訓練。


![](https://miro.medium.com/max/1400/1*ohIyK2giKKxYJPny6-1MQg.png)


訓練結果出爐，透過自己實測超過10次，下圖是經過140萬image訓練後的結果，我們明顯的發現小數據最好的大概是0\.9345，看得出來我們的小數據已經盡力了。


![](https://miro.medium.com/max/1400/1*l2opVm0rDBEFwZgAa1wN8Q.png)

### **延伸思考**

透過前三集我們可以知道，若是我們直接train小數據的話，accuracy 大概落在63%上下，用了資料增強\(Data augmentation\)可以達到78%，再加上Dropout、batch normalization可以達到85%，最後再透過transfer learning可以達到93%，我們一步不的帶著大家如何從手足無措的小孩，慢慢轉大人變成一個可以獨當一面的大人，而現實中真的有這麼輕鬆可以解決百病的方法嗎？因此下一篇我們會來聊聊 object detection，請讓大家用輕鬆的心理繼續看歐巴說故事吧～


![對der ~](https://miro.medium.com/max/1400/1*nMtc14Rx8E831BgxvhJYlQ.gif)

對der ~
#### 終於寫完了…\.

感想，環境用的好，Training 沒煩腦，環境用不好，Training到你老。

希望大家看完能對ＣＶ與ＡＩ有更加認識，如果你有看完全部的小數據介紹你真的是champion了～

We are the champion~ my friend~


![](https://miro.medium.com/max/1400/1*nEduJGwkxObs3RxVGXdvSw.jpeg)


終於寫完 刺槍術 全集了

下一個寫的目標將會是 object detection\.

難易度會拉高很多

但我會一樣用說故事的方法

來聊這個議題

因為我覺得ＡＩ不應該是B2B

更應該貼近於 App store的 B2C


[![YOLOv2 Demonstration on Coincidance in Taipei](/assets/de47a58680d5/1d01_hqdefault.jpg "YOLOv2 Demonstration on Coincidance in Taipei")](http://www.youtube.com/watch?v=QCdmmWh8I8o){:target="_blank"}




_[Post](https://medium.com/@jackycsie/%E5%B0%8F%E6%95%B8%E6%93%9A-bang-bang-bang-de47a58680d5){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
