---
title: "小數據的逆襲"
author: "黃馨平"
date: 2019-01-19T08:06:03.099+0000
last_modified_at: 2019-01-25T03:26:30.530+0000
categories: [""]
tags: []
description: "大家好我是工科先生，Jacky。"
render_with_liquid: false
---

### 小數據的逆襲 ?


![](https://miro.medium.com/max/1400/1*r0EORsgeNrO6_lJ3WMoRoQ.jpeg)


大家好我是母湯先生，Jacky。

上一次跟大家介紹完上擊以後 =&gt; [小數據的大平台](https://medium.com/@jackycsie/小數據的大平台-f555d1eb6e34?fbclid=IwAR2ftfxPqu5NIKC2FfNJXbRu0sf86icesX79knky9z5nQEDUqyknwz9IQQw){:target="_blank"} 。

這集要跟大家聊聊做完資料增強以後\(Data Augmentation\)，我們怎麼把它套入到我們的深度學習模型中。

在本篇文章將給大家三個大方向
1. 示範小數據餵入到model以後，所造成的overfitting，我們可以如何解決。
2. 實測透過data augmentation解決overfitting的效果表現。
3. 過dropout, batch normalization, data augmentation後的輸出結果是否比前面兩者來得更好。


那我們來開始吧！


![](https://miro.medium.com/max/1400/1*fcwLWixk10G27dEqiHOM-Q.gif)

### 一、資料集

我們使用的資料集是 [kaggle](https://www.kaggle.com/c/dogs-vs-cats/data){:target="_blank"} 提供的資料，該原始數據集包含25,000張狗和貓的圖像\(每個類別12,500個\)，但是這是官方提供的資料，而我們為了模擬小數據集時所碰到的難題，我們訓練集只拿出2000張貓與狗的image\(各1000張\)，驗證集以及測試集各1000張，下圖是loading資料過後的結果。


![](https://miro.medium.com/max/1400/1*3WEaPSNTC7CbIzLyDFuVzA.png)

### 二、資料預處理 \(Data Preprocessing\)

當我們得知我們圖片的內容無誤後，我們該如何將圖片轉換成模型能夠讀入的資料呢？我們透過下列四個步驟去完成我們想要的任務。
- 讀進image檔案。
- 將image內容解碼為RGB的像素。
- 將image轉換成浮點張量。
- 最後將像素值（ 0和255之間）重新縮放到\[0,1\]間隔，方便deep learning做運算。


以下我們透過程式碼介紹我們是如何做到資料預處理的。

Keras有一個圖像處理工具的module，位於 `keras.preprocessing.image` 。當中的 `ImageDataGenerator` 類別，可以快速的自動將disk上的圖像文件轉換成tensors。我們將在這裡使用這個工具。

使用ImageDataGenerator的 **好處** 在於Keras並不是在記憶體中對整個圖像數據集執行圖像轉換操作以及儲存，而是設計為通過深度學習模型訓練過程進行迭代，從而為您動態地創建增強的圖像數據。這會減少您的記憶體開銷，但在模型訓練期間會增加一些額外的時間成本。
```
from keras.preprocessing.image import ImageDataGenerator
# 透過下列方式可以將所有的image做正規化。
train_datagen = ImageDataGenerator(rescale=1./255)
```

讓我們看一下當做完上述的程式碼後我們shape後出來的值會是多少。
```
for data_batch, labels_batch in train_generator:
    print('data batch shape:', data_batch.shape)
    print('labels batch shape:', labels_batch.shape)
    break
```


![](https://miro.medium.com/max/1400/1*aa8PwcD-g9ftf_5qG9Mv9g.png)


我們會出現每次20批次的大小130\*130的相片。

OK 做完了圖片的前處理後我們開始我們的重頭戲開始來建立model吧～
### 三、建立模型


![](https://miro.medium.com/max/1400/1*R-ItxBW2SWarITBKe7HZuA.gif)


沒錯～我們想要建立一個可以識別狗跟貓圖片的model，那這麼多的模型我們會選擇哪種呢？

我想有基礎深度學習概念的大大們，第一個想法就是拿卷積神經網路\(CNN\)下去試試看，卷積神經網路有幾個優點。
1. 共享卷積核，對高維資料處理無壓力。
2. 不需要手動選取特徵，訓練好權重，即得特徵分類效果好。
3. 對圖片識別特別有效，卷積的根本目的是從輸入圖片中提取特徵。卷積用一個小方格的數據學習圖像特徵，可以保留像素之間的空間關係。


因上述幾種因素我們這次選擇的model也是用基於CNN概念的改良版，來看一下CNN的model長怎樣。


![](https://miro.medium.com/max/1400/1*wqK75XKEdrDf1ZnWk9eLMQ.jpeg)


對不起 XDD，放錯張不是這個model，也不是那個CNN，是下面這個。


![](https://miro.medium.com/max/1400/1*3-9maz8Cgr5eIQNZnFODaA.png)


在本次實驗中我們使用的是High\-level API keras，底層是tensorflow在運行，為什麼不直接使用tensorflow呢？簡單的原因在於我們沒有要實作非常困難或者需要自行定義loss function,GD等等複雜的運算，因此我們用keras簡單快速。

下面是我們使用keras functional api 所建立出來的模型。


![](https://miro.medium.com/max/1400/1*NKA8O6Pdtc5wbPPvzS2TNA.png)


Input以後會有兩層的convolutional layer提取feature，接下來做降維的max pooling，重複兩次動作以後，做flatten並且再接一個FCN最後output成為1維的輸出。

下面是我們的程式碼。
```
target_number = 130
image_input = Input(shape=(target_number, target_number, 3), name='input')
conv1 = Conv2D(3, kernel_size=3, activation='relu', name='conv1')(image_input)
conv2 = Conv2D(10, kernel_size=3, activation='relu', name='conv2')(conv1)
pool1 = MaxPool2D(pool_size=(2, 2), strides=(2,2), name='pool1')(conv2)
conv3 = Conv2D(3, kernel_size=3, activation='relu', name='conv3')(pool1)
conv4 = Conv2D(5, kernel_size=3, activation='relu', name='conv4')(conv3)
pool2 = MaxPool2D(pool_size=(3, 3), strides=(2,2), name='pool2')(conv4)
flatten1 = Flatten(name='flatten1')(pool2)
```

既然寫完了build完我們就開始來跑跑看我們的model的效果如何吧～

run~

model

run~


![](https://miro.medium.com/max/1400/1*IxS_lKi5m1FXOkLU8toRzA.gif)

#### 沒有使用資料增強\(Data augmentation\)的dataset

由下圖可以看到沒有使用資料增強的dataset，就像電影越來越愛你\(la la land\)兩個不回頭的情人，越走越遠了，因為它們overfitting了，validation data的acc都沒有超過65%以上，loss 也越來越高。


![](https://miro.medium.com/max/1400/1*quy-b2OTGmdDSyofMmJafg.gif)



![](https://miro.medium.com/max/1400/1*-VX9eO7fB6w7AJ_XsiJMsw.png)

#### 使用資料增強\(Data augmentation\)的dataset

說了這麼多，我們的重頭戲終於來了

首先來看一下我們keras使用那些 ImageDataGenerator來做資料的加強。


![](https://miro.medium.com/max/1400/1*bbzlk1ob6Dxc8vrPpzI6gw.png)

```
train_generator = ImageDataGenerator(
        rotation_range=15,
        rescale=1./255,
        shear_range=0.1,
        zoom_range=0.2,
        horizontal_flip=True,
        width_shift_range=0.1,
        height_shift_range=0.1)
```

假設我們model\.fit的steps\_per\_epoch設定為100,epoch設為50,batch\_size設定為32，那32\*100\*50等於160,000，就等於了我們讓這個model訓練了160,000張照片，是不是一件很酷的事情，從原本只有2000張照片變成80倍的資料集，這就是 **資料科學家迷人的地方** 。

而我們的model跟上一個model，一模模一樣樣，讓我們來看看只做了一個小小的改變，能變成怎樣的結果。

各位觀眾！！！！

從下圖可以容易地看出，我們的資料完全沒有如剛剛overfitting那種誇張的分離，並且我們的validation acc足足提升了10%以上，loss value也持續地跟train loss value一樣不段的在下降，這兩條原本看似永不相愛的戀人，變成了像真愛每一天\(about time\)的情人一樣緊緊相依，請各位掌聲加尖叫，謝謝。


![](https://miro.medium.com/max/1400/1*6jO8kYLbWZhl8Hq4PRHu3g.gif)



![](https://miro.medium.com/max/1400/1*p19MYHlF6v_D05vT7OpQCA.png)


大家看到這裡就過癮了嗎？？

我想我們可以試試更多不一樣的選擇來去解決overfitting的方式，在接下來我們會使用dropout，batch normalization, data augmentation，做結合，來看看結合這麼多的方法會不會像航海王的黑鬍子一樣變得這麼的powerful，讓我們繼續看下去。

下集待續…


![](https://miro.medium.com/max/1400/1*UMCcCJn9q9z2AKFkEKoF0A.jpeg)


被我騙到了吧～ 別慌下集不就來了嗎～

**使用dropout以及batch normalization提升accuracy**

上述這兩種方法是資料科學家常用來提升accuracy，或這是降低loss時常用的手法，另外其實還有L1 L2 regularization，但因為這對新手來說太難所以這次沒有放進去介紹。

為了應映新的方法，我們改變了model的架構，下圖我們的model是參考Uysim大大寫的，用的方法就是很basic的Conv \+ BatchNorm \+ mac pooling \+ Dropout，做三次卻可以得到驚人的效果。


![](https://miro.medium.com/max/1400/1*UpeTRw2c5ugo-Hfe4eT9qw.jpeg)


下面的程式碼是透過keras functional api完成上述的model。
```

mage_input = Input(shape=(target_number, target_number, 3), name='input')
conv1 = Conv2D(32, kernel_size=3, activation='relu', name='conv1')(image_input)
bn1 = BatchNormalization()(conv1)
pool1 = MaxPool2D(pool_size=(2, 2), name='pool1')(bn1)
drop1 = Dropout(0.25, name='drop1')(pool1)
conv2 = Conv2D(64, kernel_size=3, activation='relu', name='conv2')(drop1)
bn2 = BatchNormalization()(conv2)
pool2 = MaxPool2D(pool_size=(2, 2), name='pool2')(bn2)
drop2 = Dropout(0.25, name='drop2')(pool2)
conv3 = Conv2D(128, kernel_size=3, activation='relu', name='conv3')(drop2)
bn3 = BatchNormalization()(conv3)
pool3 = MaxPool2D(pool_size=(2, 2), name='pool3')(bn3)
drop3 = Dropout(0.25, name='drop3')(pool3)
flatten1 = Flatten(name='flatten1')(drop3)
```

建立完model以後來讓我們看看見證奇蹟的時刻吧！


![](https://miro.medium.com/max/1400/1*CHaz5jE9EgaxWeoA-i6u9g.png)


從上圖中我們一樣的看到了overfitting，就像浩子說的人一直走對的路也不是辦法，做機器學習當然也不是幾個簡單的方法套一套就可以做到有如夢幻般的神力，但還是有好事情發生的雖然我們的model依舊overfitting，但是我們的validation acc已經可以提升到將近80~85%以上的水準，比起過去的數據還是有相當不錯的水準，by the way 如果我們原本的dataset有20000筆資料我們的model在validation acc可以到90%的成績。

另外看一下我們做的confusion matrix資料，雖然數據量還不夠客觀但可以讓大家看看漂亮的圖片～


![](https://miro.medium.com/max/1400/1*OzvpAdQ1m1DSny2wfS1emg.png)

### **四、圖片視覺化**

圖片視覺化是做影像識別中最迷人也最著迷的部分，透過它你就像007 詹姆士龐德穿著西裝演動作片，而忘了你只是個清槍開始、清槍蹲下的二等兵。

下圖是我們將圖片轉換成RGB以後的照片，那大家一定在想經過convolutional的貓咪它的特徵萃取是怎樣的呢？我們給大家看幾張照片。


![](https://miro.medium.com/max/1400/1*H7dicFtH76wfjQ75W2zR9Q.png)


下圖是第一層layer再經過convolutional後的機器會去識別的輪廓，我知道大家看不太到所以放大了一張給大家喬個仔細。


![](https://miro.medium.com/max/1400/1*tpSxK3pckYG7YjDC2xLE_A.png)


沒錯下圖就是放大後的照片，長得超像埃及壁畫一樣，但是還是蠻酷的實驗，其實還有很多有趣的視覺化可以試試，透過openCV可以還原當初深度學習訓練時的案發現場，這種感覺就像是貓吸到貓薄荷一樣有趣。


![](https://miro.medium.com/max/1400/1*B648DHQXpg1MvKA35-oEKQ.png)

### 五、總結

透過了上述的幾種講解我們可以得知小數據的確還是有機會做到不錯的成果，但是仍然有它的限制在，所以資料還是盡可能的收集才是解決之道，當然機器學習的基礎學習也是必要的。

寫完了上擊與衝擊後，接下來我們就是要朝向砍劈了，在這部分我還在思考大家比較想要看我們應用在Apple ios ML中，還是想要做遷移式學習\(transfer learning\)？

下一集 =&gt; [小數據 bang bang bang](../de47a58680d5/) 。

謝謝大家


![](https://miro.medium.com/max/1400/1*L_hECYxeYD_Zbk7kld8h_g.jpeg)


總算寫完了…

其實難的不是寫文章

而是環境問題, train了大概3,40次有吧\. \.



_[Post](https://medium.com/@jackycsie/%E5%B0%8F%E6%95%B8%E6%93%9A%E7%9A%84%E9%80%86%E8%A5%B2-c04fee852539){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
