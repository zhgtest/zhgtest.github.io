<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Ubuntu 透過 Ansible 部署 CEPH" /><meta name="author" content="黃馨平" /><meta property="og:locale" content="en" /><meta name="description" content="本篇會介紹如何在 ubuntu system 透過 ceph-ansible 工具安裝一個 ceph 叢集。" /><meta property="og:description" content="本篇會介紹如何在 ubuntu system 透過 ceph-ansible 工具安裝一個 ceph 叢集。" /><link rel="canonical" href="https://medium-to-jekyll-starter.zhgchg.li//posts/6a4af7a1f208/" /><meta property="og:url" content="https://medium-to-jekyll-starter.zhgchg.li//posts/6a4af7a1f208/" /><meta property="og:site_name" content="Medium To Jekyll Starter" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-04-15T10:29:16+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Ubuntu 透過 Ansible 部署 CEPH" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@黃馨平" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"黃馨平"},"dateModified":"2020-05-22T15:25:17+08:00","datePublished":"2020-04-15T10:29:16+08:00","description":"本篇會介紹如何在 ubuntu system 透過 ceph-ansible 工具安裝一個 ceph 叢集。","headline":"Ubuntu 透過 Ansible 部署 CEPH","mainEntityOfPage":{"@type":"WebPage","@id":"https://medium-to-jekyll-starter.zhgchg.li//posts/6a4af7a1f208/"},"url":"https://medium-to-jekyll-starter.zhgchg.li//posts/6a4af7a1f208/"}</script><title>Ubuntu 透過 Ansible 部署 CEPH | Medium To Jekyll Starter</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Medium To Jekyll Starter"><meta name="application-name" content="Medium To Jekyll Starter"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script src="/assets/js/dist/theme.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js?baseurl=&register=true" ></script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/avatar.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a> <a class="site-title d-block" href="/">Medium To Jekyll Starter</a><p class="site-subtitle fst-italic mb-0">A text-focused Jekyll theme</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/github_username" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener noreferrer" > <i class="fa-brands fa-x-twitter"></i> </a> <a href="javascript:location.href = 'mailto:' + ['example','domain.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>Ubuntu 透過 Ansible 部署 CEPH</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1" data-toc="true"><header><h1 data-toc-skip>Ubuntu 透過 Ansible 部署 CEPH</h1><p class="post-desc fw-light mb-4">本篇會介紹如何在 ubuntu system 透過 ceph-ansible 工具安裝一個 ceph 叢集。</p><div class="post-meta text-muted"> <span> Posted <time data-ts="1586917756" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Apr 15, 2020 </time> </span> <span> Updated <time data-ts="1590132317" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > May 22, 2020 </time> </span><div class="d-flex justify-content-between"> <span> By <em> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="5434 words" > <em>30 min</em> read</span></div></div></div></header><div id="toc-bar" class="d-flex align-items-center justify-content-between invisible"> <span class="label text-truncate">Ubuntu 透過 Ansible 部署 CEPH</span> <button type="button" class="toc-trigger btn me-1"> <i class="fa-solid fa-list-ul fa-fw"></i> </button></div><button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm"> <span class="label ps-2 pe-1">Contents</span> <i class="fa-solid fa-angle-right fa-fw"></i> </button> <dialog id="toc-popup" class="p-0"><div class="header d-flex flex-row align-items-center justify-content-between"><div class="label text-truncate py-2 ms-4">Ubuntu 透過 Ansible 部署 CEPH</div><button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75"> <i class="fas fa-close"></i> </button></div><div id="toc-popup-content" class="px-4 py-3 pb-4"></div></dialog><div class="content"><h3 id="ubuntu-透過-ansible-部署-ceph"><span class="me-2">[Ubuntu] 透過 Ansible 部署 CEPH</span><a href="#ubuntu-透過-ansible-部署-ceph" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="https://miro.medium.com/max/1400/1*jOLqbm0Slm8z18wrZv6RgA.jpeg" class="popup img-link shimmer"><img src="https://miro.medium.com/max/1400/1*jOLqbm0Slm8z18wrZv6RgA.jpeg" alt="" loading="lazy"></a></p><p>本篇會介紹如何透過 ceph-ansible 工具安裝一個 ceph 叢集，使用的環境是 ubuntu 18.04 LTS ，一個最簡單的 Ceph 儲存叢集至少要一台 <code class="language-plaintext highlighter-rouge">Monitor</code> 與三台 <code class="language-plaintext highlighter-rouge">OSD</code> 。而 MDS 是當需要使用到 CephFS 的時候才需要部署。</p><h3 id="1環境準備"><span class="me-2">1.環境準備</span><a href="#1環境準備" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>本次安裝會擁有 5 台 node，叢集拓樸圖如下所示：</p><p><a href="https://miro.medium.com/max/1400/1*VYSs_Wp2K1uZeqOlOdcDVw.png" class="popup img-link shimmer"><img src="https://miro.medium.com/max/1400/1*VYSs_Wp2K1uZeqOlOdcDVw.png" alt="" loading="lazy"></a></p><h3 id="tips"><span class="me-2">Tips:</span><a href="#tips" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>每一台 server 都需要安裝，NTP package。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>$ apt install -y ntp
</pre></table></code></div></div><ul><li>每一台 hostname 必須先設定成未來 host 連接時一樣的名稱。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>$ hostnamectl set-hostname {你想要的 hostname}
</pre></table></code></div></div><p><a href="https://miro.medium.com/max/1400/1*yU55i28uG2ZC1shkt-Usww.jpeg" class="popup img-link shimmer"><img src="https://miro.medium.com/max/1400/1*yU55i28uG2ZC1shkt-Usww.jpeg" alt="" loading="lazy"></a></p><ul><li>Ansible Node 先設定好可以直接不須密碼連進其他台 node(server) .</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>$ ssh-keygen
$ ssh-copy-id root@ceph-node[1-4]
</pre></table></code></div></div><h3 id="2安裝-ansible"><span class="me-2">2.安裝 Ansible</span><a href="#2安裝-ansible" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>在 Ceph-Ansible 節點上安裝 ansible 工具。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>root@ceph-ansible:~# apt-get install -y software-properties-common git cowsay
</pre></table></code></div></div><ul><li>在 Ceph-Ansible 節點中，輸入以下內容。</ul><p><a href="https://miro.medium.com/max/1400/1*qAiqEOXp-NtYCXS6Q4l7Fg.jpeg" class="popup img-link shimmer"><img src="https://miro.medium.com/max/1400/1*qAiqEOXp-NtYCXS6Q4l7Fg.jpeg" alt="" loading="lazy"></a></p><ul><li>透過 ansible ping 指令，檢查是否有設置正確 hosts。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>root@ceph-ansible:~# ansible all -m ping
</pre></table></code></div></div><p><a href="https://miro.medium.com/max/1400/1*nKQX2M4Hhqk2Jpjwt3kACQ.jpeg" class="popup img-link shimmer"><img src="https://miro.medium.com/max/1400/1*nKQX2M4Hhqk2Jpjwt3kACQ.jpeg" alt="" loading="lazy"></a></p><h3 id="3透過-ceph-ansible-部屬-ceph-叢集"><span class="me-2">3.透過 Ceph-Ansible 部屬 Ceph 叢集</span><a href="#3透過-ceph-ansible-部屬-ceph-叢集" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>下載 ceph-aisible，轉 branch 到 stable-5.0，安裝必要檔案。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>root@ceph-ansible:~# git clone "https://github.com/ceph/ceph-ansible.git"
root@ceph-ansible:~# cd ceph-ansible
root@ceph-ansible:~/ceph-ansible# git checkout -b origin/stable-5.0
</pre></table></code></div></div><p><a href="https://miro.medium.com/max/1400/1*NObasYKjPv8f1EHcIu4C7A.jpeg" class="popup img-link shimmer"><img src="https://miro.medium.com/max/1400/1*NObasYKjPv8f1EHcIu4C7A.jpeg" alt="" loading="lazy"></a></p><ul><li>，將 sample 檔轉成 yaml 檔案。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>root@ceph-ansible:~/ceph-ansible# cp site.yml.sample site.yml
root@ceph-ansible:~/ceph-ansible# cp group_vars/all.yml.sample group_vars/all.yml
root@ceph-ansible:~/ceph-ansible# cp group_vars/osds.yml.sample group_vars/osds.yml
</pre></table></code></div></div><ul><li>修改 group_vars/all.yml 中的配置。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>50: mon_group_name: mons
51: osd_group_name: osds
65: configure_firewall: False
103: ntp_daemon_type: ntpd
125: ceph_origin: repository
132: ceph_repository: community
146: ceph_mirror: http://download.ceph.com
147: ceph_stable_key: https://download.ceph.com/keys/release.asc
148: ceph_stable_release: octopus
149: ceph_stable_repo: "{{ ceph_mirror }}/debian-{{ ceph_stable_release }}"
</pre></table></code></div></div><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384
385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439
440
441
442
443
444
445
446
447
448
449
450
451
452
453
454
455
456
457
458
459
460
461
462
463
464
465
466
467
468
469
470
471
472
473
474
475
476
477
478
479
480
481
482
483
484
485
486
487
488
489
490
491
492
493
494
495
496
497
498
499
500
501
502
503
504
505
506
507
508
509
510
511
512
513
514
515
516
517
518
519
520
521
522
523
524
525
526
527
528
529
530
531
532
533
534
535
536
537
538
539
540
541
542
543
544
545
546
547
548
549
550
551
552
553
554
555
556
557
558
559
560
561
562
563
564
565
566
567
568
569
570
571
572
573
574
575
576
577
578
579
580
581
582
583
584
585
586
587
588
589
590
591
592
593
594
595
596
597
598
599
600
601
602
603
604
605
606
607
608
609
610
611
612
613
614
615
616
617
618
619
620
621
622
623
624
625
626
627
628
629
630
631
632
633
634
635
636
637
638
639
640
641
642
643
644
645
646
647
648
649
650
651
652
653
654
655
656
657
658
659
660
661
662
663
664
665
666
667
668
669
670
671
672
673
674
675
676
677
678
679
680
681
682
683
684
685
686
687
688
689
690
691
692
693
694
695
696
697
698
699
700
701
702
703
704
705
706
707
708
709
710
711
712
713
714
715
716
717
718
719
720
721
722
723
724
725
726
727
728
729
730
731
732
733
734
735
736
737
738
739
740
741
742
743
744
745
746
747
748
749
750
751
752
753
754
755
756
757
758
759
760
761
762
763
764
765
766
767
768
769
770
771
772
773
774
775
776
777
778
779
780
781
782
783
784
785
786
787
788
789
790
791
792
793
794
795
796
797
798
799
800
801
802
803
804
805
806
807
808
809
810
811
812
813
814
815
816
817
818
819
820
821
822
823
</pre><td class="rouge-code"><pre><span class="nn">---</span>
<span class="c1"># Variables here are applicable to all host groups NOT roles</span>

<span class="c1"># This sample file generated by generate_group_vars_sample.sh</span>

<span class="c1"># Dummy variable to avoid error because ansible does not recognize the</span>
<span class="c1"># file as a good configuration file when no variable in it.</span>
<span class="na">dummy</span><span class="pi">:</span>

<span class="c1"># You can override vars by using host or group vars</span>

<span class="c1">###########</span>
<span class="c1"># GENERAL #</span>
<span class="c1">###########</span>

<span class="c1">######################################</span>
<span class="c1"># Releases name to number dictionary #</span>
<span class="c1">######################################</span>
<span class="c1">#ceph_release_num:</span>
<span class="c1">#  dumpling: 0.67</span>
<span class="c1">#  emperor: 0.72</span>
<span class="c1">#  firefly: 0.80</span>
<span class="c1">#  giant: 0.87</span>
<span class="c1">#  hammer: 0.94</span>
<span class="c1">#  infernalis: 9</span>
<span class="c1">#  jewel: 10</span>
<span class="c1">#  kraken: 11</span>
<span class="c1">#  luminous: 12</span>
<span class="c1">#  mimic: 13</span>
<span class="c1">#  nautilus: 14</span>
<span class="c1">#  octopus: 15</span>
<span class="c1">#  pacific: 16</span>
<span class="c1">#  dev: 99</span>

<span class="c1"># Directory to fetch cluster fsid, keys etc...</span>
<span class="c1">#fetch_directory: fetch/</span>

<span class="c1"># The 'cluster' variable determines the name of the cluster.</span>
<span class="c1"># Changing the default value to something else means that you will</span>
<span class="c1"># need to change all the command line calls as well, for example if</span>
<span class="c1"># your cluster name is 'foo':</span>
<span class="c1"># "ceph health" will become "ceph --cluster foo health"</span>
<span class="c1">#</span>
<span class="c1"># An easier way to handle this is to use the environment variable CEPH_ARGS</span>
<span class="c1"># So run: "export CEPH_ARGS="--cluster foo"</span>
<span class="c1"># With that you will be able to run "ceph health" normally</span>
<span class="c1">#cluster: ceph</span>

<span class="c1"># Inventory host group variables</span>
<span class="na">mon_group_name</span><span class="pi">:</span> <span class="s">mons</span>
<span class="na">osd_group_name</span><span class="pi">:</span> <span class="s">osds</span>
<span class="c1">#rgw_group_name: rgws</span>
<span class="c1">#mds_group_name: mdss</span>
<span class="c1">#nfs_group_name: nfss</span>
<span class="c1">#rbdmirror_group_name: rbdmirrors</span>
<span class="c1">#client_group_name: clients</span>
<span class="c1">#iscsi_gw_group_name: iscsigws</span>
<span class="c1">#mgr_group_name: mgrs</span>
<span class="c1">#rgwloadbalancer_group_name: rgwloadbalancers</span>
<span class="c1">#grafana_server_group_name: grafana-server</span>

<span class="c1"># If configure_firewall is true, then ansible will try to configure the</span>
<span class="c1"># appropriate firewalling rules so that Ceph daemons can communicate</span>
<span class="c1"># with each others.</span>
<span class="na">configure_firewall</span><span class="pi">:</span> <span class="s">False</span>

<span class="c1"># Open ports on corresponding nodes if firewall is installed on it</span>
<span class="c1">#ceph_mon_firewall_zone: public</span>
<span class="c1">#ceph_mgr_firewall_zone: public</span>
<span class="c1">#ceph_osd_firewall_zone: public</span>
<span class="c1">#ceph_rgw_firewall_zone: public</span>
<span class="c1">#ceph_mds_firewall_zone: public</span>
<span class="c1">#ceph_nfs_firewall_zone: public</span>
<span class="c1">#ceph_rbdmirror_firewall_zone: public</span>
<span class="c1">#ceph_iscsi_firewall_zone: public</span>
<span class="c1">#ceph_dashboard_firewall_zone: public</span>
<span class="c1">#ceph_rgwloadbalancer_firewall_zone: public</span>

<span class="c1"># Generate local ceph.conf in fetch directory</span>
<span class="c1">#ceph_conf_local: false</span>

<span class="c1">############</span>
<span class="c1"># PACKAGES #</span>
<span class="c1">############</span>
<span class="c1">#debian_package_dependencies: []</span>

<span class="c1">#centos_package_dependencies:</span>
<span class="c1">#  - epel-release</span>
<span class="c1">#  - python3-libselinux</span>

<span class="c1">#redhat_package_dependencies: []</span>

<span class="c1">#suse_package_dependencies: []</span>

<span class="c1"># Whether or not to install the ceph-test package.</span>
<span class="c1">#ceph_test: false</span>

<span class="c1"># Enable the ntp service by default to avoid clock skew on ceph nodes</span>
<span class="c1"># Disable if an appropriate NTP client is already installed and configured</span>
<span class="c1">#ntp_service_enabled: true</span>

<span class="c1"># Set type of NTP client daemon to use, valid entries are chronyd, ntpd or timesyncd</span>
<span class="na">ntp_daemon_type</span><span class="pi">:</span> <span class="s">ntpd</span>

<span class="c1"># This variable determines if ceph packages can be updated.  If False, the</span>
<span class="c1"># package resources will use "state=present".  If True, they will use</span>
<span class="c1"># "state=latest".</span>
<span class="c1">#upgrade_ceph_packages: False</span>

<span class="c1">#ceph_use_distro_backports: false # DEBIAN ONLY</span>
<span class="c1">#ceph_directories_mode: "0755"</span>

<span class="c1">###########</span>
<span class="c1"># INSTALL #</span>
<span class="c1">###########</span>
<span class="c1">#ceph_repository_type: dummy</span>

<span class="c1"># ORIGIN SOURCE</span>
<span class="c1">#</span>
<span class="c1"># Choose between:</span>
<span class="c1"># - 'repository' means that you will get ceph installed through a new repository. Later below choose between 'community', 'rhcs', 'dev' or 'obs'</span>
<span class="c1"># - 'distro' means that no separate repo file will be added</span>
<span class="c1">#  you will get whatever version of Ceph is included in your Linux distro.</span>
<span class="c1"># 'local' means that the ceph binaries will be copied over from the local machine</span>

<span class="c1"># repository: 使用 Ceph upstream 的 repository</span>
<span class="c1"># distro: 使用 Linux distro 中包好的 Ceph</span>
<span class="c1"># local: 使用本地編譯好的 Ceph binary</span>
<span class="na">ceph_origin</span><span class="pi">:</span> <span class="s">repository</span>

<span class="c1">#valid_ceph_origins:</span>
<span class="c1">#  - repository</span>
<span class="c1">#  - distro</span>
<span class="c1">#  - local</span>


<span class="na">ceph_repository</span><span class="pi">:</span> <span class="s">community</span>
<span class="c1">#valid_ceph_repository:</span>
<span class="c1">#  - community</span>
<span class="c1">#  - rhcs</span>
<span class="c1">#  - dev</span>
<span class="c1">#  - uca</span>
<span class="c1">#  - custom</span>
<span class="c1">#  - obs</span>


<span class="c1"># REPOSITORY: COMMUNITY VERSION</span>
<span class="c1">#</span>
<span class="c1"># Enabled when ceph_repository == 'community'</span>
<span class="c1">#</span>
<span class="na">ceph_mirror</span><span class="pi">:</span> <span class="s">http://download.ceph.com</span>
<span class="na">ceph_stable_key</span><span class="pi">:</span> <span class="s">https://download.ceph.com/keys/release.asc</span>
<span class="na">ceph_stable_release</span><span class="pi">:</span> <span class="s">octopus</span>
<span class="na">ceph_stable_repo</span><span class="pi">:</span> <span class="s2">"</span><span class="s">{{</span><span class="nv"> </span><span class="s">ceph_mirror</span><span class="nv"> </span><span class="s">}}/debian-{{</span><span class="nv"> </span><span class="s">ceph_stable_release</span><span class="nv"> </span><span class="s">}}"</span>

<span class="c1">#nfs_ganesha_stable: true # use stable repos for nfs-ganesha</span>
<span class="c1">#nfs_ganesha_stable_branch: V3.2-stable</span>
<span class="c1">#nfs_ganesha_stable_deb_repo: "{{ ceph_mirror }}/nfs-ganesha/deb-{{ nfs_ganesha_stable_branch }}/{{ ceph_stable_release }}"</span>


<span class="c1"># Use the option below to specify your applicable package tree, eg. when using non-LTS Ubuntu versions</span>
<span class="c1"># # for a list of available Debian distributions, visit http://download.ceph.com/debian-{{ ceph_stable_release }}/dists/</span>
<span class="c1"># for more info read: https://github.com/ceph/ceph-ansible/issues/305</span>
<span class="c1">#ceph_stable_distro_source: "{{ ansible_distribution_release }}"</span>

<span class="c1"># This option is needed for _both_ stable and dev version, so please always fill the right version</span>
<span class="c1"># # for supported distros, see http://download.ceph.com/rpm-{{ ceph_stable_release }}/</span>
<span class="c1">#ceph_stable_redhat_distro: el8</span>


<span class="c1"># REPOSITORY: RHCS VERSION RED HAT STORAGE (from 5.0)</span>
<span class="c1">#</span>
<span class="c1"># Enabled when ceph_repository == 'rhcs'</span>
<span class="c1">#</span>
<span class="c1"># This version is supported on RHEL 8</span>
<span class="c1">#</span>
<span class="c1">#ceph_rhcs_version: "{{ ceph_stable_rh_storage_version | default(5) }}"</span>
<span class="c1">#valid_ceph_repository_type:</span>
<span class="c1">#  - cdn</span>
<span class="c1">#  - iso</span>
<span class="c1">#ceph_rhcs_iso_path: "{{ ceph_stable_rh_storage_iso_path | default('') }}"</span>
<span class="c1">#ceph_rhcs_mount_path: "{{ ceph_stable_rh_storage_mount_path | default('/tmp/rh-storage-mount') }}"</span>
<span class="c1">#ceph_rhcs_repository_path: "{{ ceph_stable_rh_storage_repository_path | default('/tmp/rh-storage-repo') }}" # where to copy iso's content</span>


<span class="c1"># REPOSITORY: UBUNTU CLOUD ARCHIVE</span>
<span class="c1">#</span>
<span class="c1"># Enabled when ceph_repository == 'uca'</span>
<span class="c1">#</span>
<span class="c1"># This allows the install of Ceph from the Ubuntu Cloud Archive.  The Ubuntu Cloud Archive</span>
<span class="c1"># usually has newer Ceph releases than the normal distro repository.</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#ceph_stable_repo_uca: "http://ubuntu-cloud.archive.canonical.com/ubuntu"</span>
<span class="c1">#ceph_stable_openstack_release_uca: queens</span>
<span class="c1">#ceph_stable_release_uca: "{{ ansible_distribution_release }}-updates/{{ ceph_stable_openstack_release_uca }}"</span>

<span class="c1"># REPOSITORY: openSUSE OBS</span>
<span class="c1">#</span>
<span class="c1"># Enabled when ceph_repository == 'obs'</span>
<span class="c1">#</span>
<span class="c1"># This allows the install of Ceph from the openSUSE OBS repository. The OBS repository</span>
<span class="c1"># usually has newer Ceph releases than the normal distro repository.</span>
<span class="c1">#</span>
<span class="c1">#</span>
<span class="c1">#ceph_obs_repo: "https://download.opensuse.org/repositories/filesystems:/ceph:/{{ ceph_stable_release }}/openSUSE_Leap_{{ ansible_distribution_version }}/"</span>

<span class="c1"># REPOSITORY: DEV</span>
<span class="c1">#</span>
<span class="c1"># Enabled when ceph_repository == 'dev'</span>
<span class="c1">#</span>
<span class="c1">#ceph_dev_branch: master # development branch you would like to use e.g: master, wip-hack</span>
<span class="c1">#ceph_dev_sha1: latest # distinct sha1 to use, defaults to 'latest' (as in latest built)</span>

<span class="c1">#nfs_ganesha_dev: false # use development repos for nfs-ganesha</span>

<span class="c1"># Set this to choose the version of ceph dev libraries used in the nfs-ganesha packages from shaman</span>
<span class="c1"># flavors so far include: ceph_master, ceph_jewel, ceph_kraken, ceph_luminous</span>
<span class="c1">#nfs_ganesha_flavor: "ceph_master"</span>

<span class="c1">#ceph_iscsi_config_dev: true # special repo for deploying iSCSI gateways</span>


<span class="c1"># REPOSITORY: CUSTOM</span>
<span class="c1">#</span>
<span class="c1"># Enabled when ceph_repository == 'custom'</span>
<span class="c1">#</span>
<span class="c1"># Use a custom repository to install ceph.  For RPM, ceph_custom_repo should be</span>
<span class="c1"># a URL to the .repo file to be installed on the targets.  For deb,</span>
<span class="c1"># ceph_custom_repo should be the URL to the repo base.</span>
<span class="c1">#</span>
<span class="c1">#ceph_custom_key: https://server.domain.com/ceph-custom-repo-key.asc</span>
<span class="c1">#ceph_custom_repo: https://server.domain.com/ceph-custom-repo</span>


<span class="c1"># ORIGIN: LOCAL CEPH INSTALLATION</span>
<span class="c1">#</span>
<span class="c1"># Enabled when ceph_repository == 'local'</span>
<span class="c1">#</span>
<span class="c1"># Path to DESTDIR of the ceph install</span>
<span class="c1">#ceph_installation_dir: "/path/to/ceph_installation/"</span>
<span class="c1"># Whether or not to use installer script rundep_installer.sh</span>
<span class="c1"># This script takes in rundep and installs the packages line by line onto the machine</span>
<span class="c1"># If this is set to false then it is assumed that the machine ceph is being copied onto will already have</span>
<span class="c1"># all runtime dependencies installed</span>
<span class="c1">#use_installer: false</span>
<span class="c1"># Root directory for ceph-ansible</span>
<span class="c1">#ansible_dir: "/path/to/ceph-ansible"</span>


<span class="c1">######################</span>
<span class="c1"># CEPH CONFIGURATION #</span>
<span class="c1">######################</span>

<span class="c1">## Ceph options</span>
<span class="c1">#</span>
<span class="c1"># Each cluster requires a unique, consistent filesystem ID. By</span>
<span class="c1"># default, the playbook generates one for you and stores it in a file</span>
<span class="c1"># in `fetch_directory`. If you want to customize how the fsid is</span>
<span class="c1"># generated, you may find it useful to disable fsid generation to</span>
<span class="c1"># avoid cluttering up your ansible repo. If you set `generate_fsid` to</span>
<span class="c1"># false, you *must* generate `fsid` in another way.</span>
<span class="c1"># ACTIVATE THE FSID VARIABLE FOR NON-VAGRANT DEPLOYMENT</span>
<span class="c1">#fsid: "{{ cluster_uuid.stdout }}"</span>
<span class="c1">#generate_fsid: true</span>

<span class="c1">#ceph_conf_key_directory: /etc/ceph</span>

<span class="c1">#ceph_uid: 167</span>

<span class="c1"># Permissions for keyring files in /etc/ceph</span>
<span class="c1">#ceph_keyring_permissions: '0600'</span>

<span class="c1">#cephx: true</span>

<span class="c1">## Client options</span>
<span class="c1">#</span>
<span class="c1">#rbd_cache: "true"</span>
<span class="c1">#rbd_cache_writethrough_until_flush: "true"</span>
<span class="c1">#rbd_concurrent_management_ops: 20</span>

<span class="c1">#rbd_client_directories: true # this will create rbd_client_log_path and rbd_client_admin_socket_path directories with proper permissions</span>

<span class="c1"># Permissions for the rbd_client_log_path and</span>
<span class="c1"># rbd_client_admin_socket_path. Depending on your use case for Ceph</span>
<span class="c1"># you may want to change these values. The default, which is used if</span>
<span class="c1"># any of the variables are unset or set to a false value (like `null`</span>
<span class="c1"># or `false`) is to automatically determine what is appropriate for</span>
<span class="c1"># the Ceph version with non-OpenStack workloads -- ceph:ceph and 0770</span>
<span class="c1"># for infernalis releases, and root:root and 1777 for pre-infernalis</span>
<span class="c1"># releases.</span>
<span class="c1">#</span>
<span class="c1"># For other use cases, including running Ceph with OpenStack, you'll</span>
<span class="c1"># want to set these differently:</span>
<span class="c1">#</span>
<span class="c1"># For OpenStack on RHEL, you'll want:</span>
<span class="c1">#   rbd_client_directory_owner: "qemu"</span>
<span class="c1">#   rbd_client_directory_group: "libvirtd" (or "libvirt", depending on your version of libvirt)</span>
<span class="c1">#   rbd_client_directory_mode: "0755"</span>
<span class="c1">#</span>
<span class="c1"># For OpenStack on Ubuntu or Debian, set:</span>
<span class="c1">#    rbd_client_directory_owner: "libvirt-qemu"</span>
<span class="c1">#    rbd_client_directory_group: "kvm"</span>
<span class="c1">#    rbd_client_directory_mode: "0755"</span>
<span class="c1">#</span>
<span class="c1"># If you set rbd_client_directory_mode, you must use a string (e.g.,</span>
<span class="c1"># 'rbd_client_directory_mode: "0755"', *not*</span>
<span class="c1"># 'rbd_client_directory_mode: 0755', or Ansible will complain: mode</span>
<span class="c1"># must be in octal or symbolic form</span>
<span class="c1">#rbd_client_directory_owner: ceph</span>
<span class="c1">#rbd_client_directory_group: ceph</span>
<span class="c1">#rbd_client_directory_mode: "0770"</span>

<span class="c1">#rbd_client_log_path: /var/log/ceph</span>
<span class="c1">#rbd_client_log_file: "{{ rbd_client_log_path }}/qemu-guest-$pid.log" # must be writable by QEMU and allowed by SELinux or AppArmor</span>
<span class="c1">#rbd_client_admin_socket_path: /var/run/ceph # must be writable by QEMU and allowed by SELinux or AppArmor</span>

<span class="c1">## Monitor options</span>
<span class="c1">#</span>
<span class="c1"># You must define either monitor_interface, monitor_address or monitor_address_block.</span>
<span class="c1"># These variables must be defined at least in all.yml and overrided if needed (inventory host file or group_vars/*.yml).</span>
<span class="c1"># Eg. If you want to specify for each monitor which address the monitor will bind to you can set it in your **inventory host file** by using 'monitor_address' variable.</span>
<span class="c1"># Preference will go to monitor_address if both monitor_address and monitor_interface are defined.</span>
<span class="na">monitor_interface</span><span class="pi">:</span> <span class="s">ens3</span>
<span class="c1">#monitor_address: x.x.x.x</span>
<span class="c1">#monitor_address_block: subnet</span>
<span class="c1"># set to either ipv4 or ipv6, whichever your network is using</span>
<span class="c1">#ip_version: ipv4</span>

<span class="c1">#mon_host_v1:</span>
<span class="c1">#  enabled: True</span>
<span class="c1">#  suffix: ':6789'</span>
<span class="c1">#mon_host_v2:</span>
<span class="c1">#  suffix: ':3300'</span>

<span class="c1">##########</span>
<span class="c1"># CEPHFS #</span>
<span class="c1">##########</span>
<span class="c1"># When pg_autoscale_mode is set to True, you must add the target_size_ratio key with a correct value</span>
<span class="c1"># `pg_num` and `pgp_num` keys will be ignored, even if specified.</span>
<span class="c1"># eg:</span>
<span class="c1">#  cephfs_data_pool:</span>
<span class="c1">#    name: "{{ cephfs_data if cephfs_data is defined else 'cephfs_data' }}"</span>
<span class="c1">#    pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#    pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#    rule_name: "replicated_rule"</span>
<span class="c1">#    type: 1</span>
<span class="c1">#    erasure_profile: ""</span>
<span class="c1">#    expected_num_objects: ""</span>
<span class="c1">#    application: "cephfs"</span>
<span class="c1">#    size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#    min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#    pg_autoscale_mode: False</span>
<span class="c1">#    target_size_ratio: 0.2</span>
<span class="c1">#cephfs: cephfs # name of the ceph filesystem</span>
<span class="c1">#cephfs_data_pool:</span>
<span class="c1">#  name: "{{ cephfs_data if cephfs_data is defined else 'cephfs_data' }}"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "cephfs"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#cephfs_metadata_pool:</span>
<span class="c1">#  name: "{{ cephfs_metadata if cephfs_metadata is defined else 'cephfs_metadata' }}"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "cephfs"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#cephfs_pools:</span>
<span class="c1">#  - "{{ cephfs_data_pool }}"</span>
<span class="c1">#  - "{{ cephfs_metadata_pool }}"</span>

<span class="c1">## OSD options</span>
<span class="c1">#</span>
<span class="c1">#is_hci: false</span>
<span class="c1">#hci_safety_factor: 0.2</span>
<span class="c1">#non_hci_safety_factor: 0.7</span>
<span class="c1">#osd_memory_target: 4294967296</span>
<span class="c1">#journal_size: 1024 # OSD journal size in MB</span>
<span class="c1">#block_db_size: -1 # block db size in bytes for the ceph-volume lvm batch. -1 means use the default of 'as big as possible'.</span>
<span class="na">public_network</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10.1.3.0/24"</span>
<span class="c1">#cluster_network: "{{ public_network | regex_replace(' ', '') }}"</span>
<span class="c1">#osd_mkfs_type: xfs</span>
<span class="c1">#osd_mkfs_options_xfs: -f -i size=2048</span>
<span class="c1">#osd_mount_options_xfs: noatime,largeio,inode64,swalloc</span>
<span class="na">osd_objectstore</span><span class="pi">:</span> <span class="s">bluestore</span>

<span class="c1"># Any device containing these patterns in their path will be excluded.</span>
<span class="c1">#osd_auto_discovery_exclude: "dm-*|loop*|md*|rbd*"</span>

<span class="c1"># xattrs. by default, 'filestore xattr use omap' is set to 'true' if</span>
<span class="c1"># 'osd_mkfs_type' is set to 'ext4'; otherwise it isn't set. This can</span>
<span class="c1"># be set to 'true' or 'false' to explicitly override those</span>
<span class="c1"># defaults. Leave it 'null' to use the default for your chosen mkfs</span>
<span class="c1"># type.</span>
<span class="c1">#filestore_xattr_use_omap: null</span>

<span class="c1">## MDS options</span>
<span class="c1">#</span>
<span class="c1">#mds_max_mds: 1</span>

<span class="c1">## Rados Gateway options</span>
<span class="c1">#</span>
<span class="c1">#radosgw_frontend_type: beast # For additionnal frontends see: http://docs.ceph.com/docs/nautilus/radosgw/frontends/</span>

<span class="c1">#radosgw_civetweb_port: 8080</span>
<span class="c1">#radosgw_civetweb_num_threads: 512</span>
<span class="c1">#radosgw_civetweb_options: "num_threads={{ radosgw_civetweb_num_threads }}"</span>
<span class="c1"># For additional civetweb configuration options available such as logging,</span>
<span class="c1"># keepalive, and timeout settings, please see the civetweb docs at</span>
<span class="c1"># https://github.com/civetweb/civetweb/blob/master/docs/UserManual.md</span>

<span class="c1">#radosgw_frontend_port: "{{ radosgw_civetweb_port if radosgw_frontend_type == 'civetweb' else '8080' }}"</span>
<span class="c1"># The server private key, public certificate and any other CA or intermediate certificates should be in one file, in PEM format.</span>
<span class="c1">#radosgw_frontend_ssl_certificate: ""</span>
<span class="c1">#radosgw_frontend_ssl_certificate_data: "" # certificate contents to be written to path defined by radosgw_frontend_ssl_certificate</span>
<span class="c1">#radosgw_frontend_options: "{{ radosgw_civetweb_options if radosgw_frontend_type == 'civetweb' else '' }}"</span>
<span class="c1">#radosgw_thread_pool_size: 512</span>


<span class="c1"># You must define either radosgw_interface, radosgw_address.</span>
<span class="c1"># These variables must be defined at least in all.yml and overrided if needed (inventory host file or group_vars/*.yml).</span>
<span class="c1"># Eg. If you want to specify for each radosgw node which address the radosgw will bind to you can set it in your **inventory host file** by using 'radosgw_address' variable.</span>
<span class="c1"># Preference will go to radosgw_address if both radosgw_address and radosgw_interface are defined.</span>
<span class="c1">#radosgw_interface: interface</span>
<span class="c1">#radosgw_address: x.x.x.x</span>
<span class="c1">#radosgw_address_block: subnet</span>
<span class="c1">#radosgw_keystone_ssl: false # activate this when using keystone PKI keys</span>
<span class="c1">#radosgw_num_instances: 1</span>
<span class="c1"># Rados Gateway options</span>
<span class="c1">#email_address: foo@bar.com</span>


<span class="c1">## Testing mode</span>
<span class="c1"># enable this mode _only_ when you have a single node</span>
<span class="c1"># if you don't want it keep the option commented</span>
<span class="c1">#common_single_host_mode: true</span>

<span class="c1">## Handlers - restarting daemons after a config change</span>
<span class="c1"># if for whatever reasons the content of your ceph configuration changes</span>
<span class="c1"># ceph daemons will be restarted as well. At the moment, we can not detect</span>
<span class="c1"># which config option changed so all the daemons will be restarted. Although</span>
<span class="c1"># this restart will be serialized for each node, in between a health check</span>
<span class="c1"># will be performed so we make sure we don't move to the next node until</span>
<span class="c1"># ceph is not healthy</span>
<span class="c1"># Obviously between the checks (for monitors to be in quorum and for osd's pgs</span>
<span class="c1"># to be clean) we have to wait. These retries and delays can be configurable</span>
<span class="c1"># for both monitors and osds.</span>
<span class="c1">#</span>
<span class="c1"># Monitor handler checks</span>
<span class="c1">#handler_health_mon_check_retries: 10</span>
<span class="c1">#handler_health_mon_check_delay: 20</span>
<span class="c1">#</span>
<span class="c1"># OSD handler checks</span>
<span class="c1">#handler_health_osd_check_retries: 40</span>
<span class="c1">#handler_health_osd_check_delay: 30</span>
<span class="c1">#handler_health_osd_check: true</span>
<span class="c1">#</span>
<span class="c1"># MDS handler checks</span>
<span class="c1">#handler_health_mds_check_retries: 5</span>
<span class="c1">#handler_health_mds_check_delay: 10</span>
<span class="c1">#</span>
<span class="c1"># RGW handler checks</span>
<span class="c1">#handler_health_rgw_check_retries: 5</span>
<span class="c1">#handler_health_rgw_check_delay: 10</span>

<span class="c1"># NFS handler checks</span>
<span class="c1">#handler_health_nfs_check_retries: 5</span>
<span class="c1">#handler_health_nfs_check_delay: 10</span>

<span class="c1"># RBD MIRROR handler checks</span>
<span class="c1">#handler_health_rbd_mirror_check_retries: 5</span>
<span class="c1">#handler_health_rbd_mirror_check_delay: 10</span>

<span class="c1"># MGR handler checks</span>
<span class="c1">#handler_health_mgr_check_retries: 5</span>
<span class="c1">#handler_health_mgr_check_delay: 10</span>

<span class="c1">## health mon/osds check retries/delay:</span>

<span class="c1">#health_mon_check_retries: 20</span>
<span class="c1">#health_mon_check_delay: 10</span>
<span class="c1">#health_osd_check_retries: 20</span>
<span class="c1">#health_osd_check_delay: 10</span>


<span class="c1">###############</span>
<span class="c1"># NFS-GANESHA #</span>
<span class="c1">###############</span>

<span class="c1"># Confiure the type of NFS gatway access.  At least one must be enabled for an</span>
<span class="c1"># NFS role to be useful</span>
<span class="c1">#</span>
<span class="c1"># Set this to true to enable File access via NFS.  Requires an MDS role.</span>
<span class="c1">#nfs_file_gw: false</span>
<span class="c1"># Set this to true to enable Object access via NFS. Requires an RGW role.</span>
<span class="c1">#nfs_obj_gw: "{{ False if groups.get(mon_group_name, []) | length == 0 else True }}"</span>


<span class="c1">#############</span>
<span class="c1"># MULTISITE #</span>
<span class="c1">#############</span>

<span class="c1"># Changing this value allows multisite code to run</span>
<span class="c1">#rgw_multisite: false</span>

<span class="c1"># If the desired multisite configuration involves only one realm, one zone group and one zone (per cluster), then the multisite variables can be set here.</span>
<span class="c1"># Please see README-MULTISITE.md for more information.</span>
<span class="c1">#</span>
<span class="c1"># If multiple realms or multiple zonegroups or multiple zones need to be created on a cluster then,</span>
<span class="c1"># the multisite config variables should be editted in their respective zone .yaml file and realm .yaml file.</span>
<span class="c1"># See README-MULTISITE-MULTIREALM.md for more information.</span>

<span class="c1"># The following Multi-site related variables should be set by the user.</span>
<span class="c1">#</span>
<span class="c1"># rgw_zone is set to "default" to enable compression for clusters configured without rgw multi-site</span>
<span class="c1"># If multisite is configured, rgw_zone should not be set to "default".</span>
<span class="c1">#</span>
<span class="c1">#rgw_zone: default</span>

<span class="c1">#rgw_zonemaster: true</span>
<span class="c1">#rgw_zonesecondary: false</span>
<span class="c1">#rgw_zonegroup: solarsystem # should be set by the user</span>
<span class="c1">#rgw_zonegroupmaster: true</span>
<span class="c1">#rgw_zone_user: zone.user</span>
<span class="c1">#rgw_zone_user_display_name: "Zone User"</span>
<span class="c1">#rgw_realm: milkyway # should be set by the user</span>
<span class="c1">#rgw_multisite_proto: "http"</span>
<span class="c1">#system_access_key: 6kWkikvapSnHyE22P7nO # should be re-created by the user</span>
<span class="c1">#system_secret_key: MGecsMrWtKZgngOHZdrd6d3JxGO5CPWgT2lcnpSt # should be re-created by the user</span>

<span class="c1"># Multi-site remote pull URL variables</span>
<span class="c1">#rgw_pull_port: "{{ radosgw_frontend_port }}"</span>
<span class="c1">#rgw_pull_proto: "http" # should be the same as rgw_multisite_proto for the master zone cluster</span>
<span class="c1">#rgw_pullhost: localhost # rgw_pullhost only needs to be declared if there is a zone secondary.</span>

<span class="c1">###################</span>
<span class="c1"># CONFIG OVERRIDE #</span>
<span class="c1">###################</span>

<span class="c1"># Ceph configuration file override.</span>
<span class="c1"># This allows you to specify more configuration options</span>
<span class="c1"># using an INI style format.</span>
<span class="c1">#</span>
<span class="c1"># When configuring RGWs, make sure you use the form [client.rgw.*]</span>
<span class="c1"># instead of [client.radosgw.*].</span>
<span class="c1"># For more examples check the profiles directory of https://github.com/ceph/ceph-ansible.</span>
<span class="c1">#</span>
<span class="c1"># The following sections are supported: [global], [mon], [osd], [mds], [client]</span>
<span class="c1">#</span>
<span class="c1"># Example:</span>
<span class="c1"># ceph_conf_overrides:</span>
<span class="c1">#   global:</span>
<span class="c1">#     foo: 1234</span>
<span class="c1">#     bar: 5678</span>
<span class="c1">#   "client.rgw.{{ hostvars[groups.get(rgw_group_name)[0]]['ansible_hostname'] }}":</span>
<span class="c1">#     rgw_zone: zone1</span>
<span class="c1">#</span>
<span class="c1">#ceph_conf_overrides: {}</span>


<span class="c1">#############</span>
<span class="c1"># OS TUNING #</span>
<span class="c1">#############</span>

<span class="c1">#disable_transparent_hugepage: "{{ false if osd_objectstore == 'bluestore' else true }}"</span>
<span class="c1">#os_tuning_params:</span>
<span class="c1">#  - { name: fs.file-max, value: 26234859 }</span>
<span class="c1">#  - { name: vm.zone_reclaim_mode, value: 0 }</span>
<span class="c1">#  - { name: vm.swappiness, value: 10 }</span>
<span class="c1">#  - { name: vm.min_free_kbytes, value: "{{ vm_min_free_kbytes }}" }</span>

<span class="c1"># For Debian &amp; Red Hat/CentOS installs set TCMALLOC_MAX_TOTAL_THREAD_CACHE_BYTES</span>
<span class="c1"># Set this to a byte value (e.g. 134217728)</span>
<span class="c1"># A value of 0 will leave the package default.</span>
<span class="c1">#ceph_tcmalloc_max_total_thread_cache: 0</span>


<span class="c1">##########</span>
<span class="c1"># DOCKER #</span>
<span class="c1">##########</span>
<span class="c1">#ceph_docker_image: "ceph/daemon"</span>
<span class="c1">#ceph_docker_image_tag: latest</span>
<span class="c1">#ceph_docker_registry: docker.io</span>
<span class="c1">#ceph_docker_registry_auth: false</span>
<span class="c1">#ceph_docker_registry_username:</span>
<span class="c1">#ceph_docker_registry_password:</span>
<span class="c1">## Client only docker image - defaults to {{ ceph_docker_image }}</span>
<span class="c1">#ceph_client_docker_image: "{{ ceph_docker_image }}"</span>
<span class="c1">#ceph_client_docker_image_tag: "{{ ceph_docker_image_tag }}"</span>
<span class="c1">#ceph_client_docker_registry: "{{ ceph_docker_registry }}"</span>
<span class="c1">#ceph_docker_enable_centos_extra_repo: false</span>
<span class="c1">#ceph_docker_on_openstack: false</span>
<span class="c1">#containerized_deployment: False</span>
<span class="c1">#container_binary:</span>
<span class="c1">#timeout_command: "{{ 'timeout --foreground -s KILL ' ~ docker_pull_timeout if (docker_pull_timeout != '0') and (ceph_docker_dev_image is undefined or not ceph_docker_dev_image) else '' }}"</span>


<span class="c1"># this is only here for usage with the rolling_update.yml playbook</span>
<span class="c1"># do not ever change this here</span>
<span class="c1">#rolling_update: false</span>

<span class="c1">#####################</span>
<span class="c1"># Docker pull retry #</span>
<span class="c1">#####################</span>
<span class="c1">#docker_pull_retry: 3</span>
<span class="c1">#docker_pull_timeout: "300s"</span>


<span class="c1">#############</span>
<span class="c1"># OPENSTACK #</span>
<span class="c1">#############</span>
<span class="c1">#openstack_config: false</span>
<span class="c1"># When pg_autoscale_mode is set to True, you must add the target_size_ratio key with a correct value</span>
<span class="c1"># `pg_num` and `pgp_num` keys will be ignored, even if specified.</span>
<span class="c1"># eg:</span>
<span class="c1">#  openstack_glance_pool:</span>
<span class="c1">#    name: "images"</span>
<span class="c1">#    pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#    pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#    rule_name: "replicated_rule"</span>
<span class="c1">#    type: 1</span>
<span class="c1">#    erasure_profile: ""</span>
<span class="c1">#    expected_num_objects: ""</span>
<span class="c1">#    application: "rbd"</span>
<span class="c1">#    size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#    min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#    pg_autoscale_mode: False</span>
<span class="c1">#    target_size_ratio: 0.2</span>
<span class="c1">#openstack_glance_pool:</span>
<span class="c1">#  name: "images"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "rbd"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#openstack_cinder_pool:</span>
<span class="c1">#  name: "volumes"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "rbd"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#openstack_nova_pool:</span>
<span class="c1">#  name: "vms"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "rbd"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#openstack_cinder_backup_pool:</span>
<span class="c1">#  name: "backups"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "rbd"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#openstack_gnocchi_pool:</span>
<span class="c1">#  name: "metrics"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "rbd"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#openstack_cephfs_data_pool:</span>
<span class="c1">#  name: "manila_data"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "cephfs"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#openstack_cephfs_metadata_pool:</span>
<span class="c1">#  name: "manila_metadata"</span>
<span class="c1">#  pg_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  pgp_num: "{{ osd_pool_default_pg_num }}"</span>
<span class="c1">#  rule_name: "replicated_rule"</span>
<span class="c1">#  type: 1</span>
<span class="c1">#  erasure_profile: ""</span>
<span class="c1">#  expected_num_objects: ""</span>
<span class="c1">#  application: "cephfs"</span>
<span class="c1">#  size: "{{ osd_pool_default_size }}"</span>
<span class="c1">#  min_size: "{{ osd_pool_default_min_size }}"</span>
<span class="c1">#  pg_autoscale_mode: False</span>
<span class="c1">#openstack_pools:</span>
<span class="c1">#  - "{{ openstack_glance_pool }}"</span>
<span class="c1">#  - "{{ openstack_cinder_pool }}"</span>
<span class="c1">#  - "{{ openstack_nova_pool }}"</span>
<span class="c1">#  - "{{ openstack_cinder_backup_pool }}"</span>
<span class="c1">#  - "{{ openstack_gnocchi_pool }}"</span>
<span class="c1">#  - "{{ openstack_cephfs_data_pool }}"</span>
<span class="c1">#  - "{{ openstack_cephfs_metadata_pool }}"</span>


<span class="c1"># The value for 'key' can be a pre-generated key,</span>
<span class="c1"># e.g key: "AQDC2UxZH4yeLhAAgTaZb+4wDUlYOsr1OfZSpQ=="</span>
<span class="c1"># By default, keys will be auto-generated.</span>
<span class="c1">#</span>
<span class="c1">#openstack_keys:</span>
<span class="c1">#  - { name: client.glance, caps: { mon: "profile rbd", osd: "profile rbd pool={{ openstack_cinder_pool.name }}, profile rbd pool={{ openstack_glance_pool.name }}"}, mode: "0600" }</span>
<span class="c1">#  - { name: client.cinder, caps: { mon: "profile rbd", osd: "profile rbd pool={{ openstack_cinder_pool.name }}, profile rbd pool={{ openstack_nova_pool.name }}, profile rbd pool={{ openstack_glance_pool.name }}"}, mode: "0600" }</span>
<span class="c1">#  - { name: client.cinder-backup, caps: { mon: "profile rbd", osd: "profile rbd pool={{ openstack_cinder_backup_pool.name }}"}, mode: "0600" }</span>
<span class="c1">#  - { name: client.gnocchi, caps: { mon: "profile rbd", osd: "profile rbd pool={{ openstack_gnocchi_pool.name }}"}, mode: "0600", }</span>
<span class="c1">#  - { name: client.openstack, caps: { mon: "profile rbd", osd: "profile rbd pool={{ openstack_glance_pool.name }}, profile rbd pool={{ openstack_nova_pool.name }}, profile rbd pool={{ openstack_cinder_pool.name }}, profile rbd pool={{ openstack_cinder_backup_pool.name }}"}, mode: "0600" }</span>


<span class="c1">#############</span>
<span class="c1"># DASHBOARD #</span>
<span class="c1">#############</span>
<span class="c1">#dashboard_enabled: True</span>
<span class="c1"># Choose http or https</span>
<span class="c1"># For https, you should set dashboard.crt/key and grafana.crt/key</span>
<span class="c1"># If you define the dashboard_crt and dashboard_key variables, but leave them as '',</span>
<span class="c1"># then we will autogenerate a cert and keyfile</span>
<span class="c1">#dashboard_protocol: http</span>
<span class="c1">#dashboard_port: 8443</span>
<span class="c1">#dashboard_admin_user: admin</span>
<span class="c1">#dashboard_admin_user_ro: false</span>
<span class="c1"># This variable must be set with a strong custom password when dashboard_enabled is True</span>
<span class="na">dashboard_admin_password</span><span class="pi">:</span> <span class="s">password</span>
<span class="c1"># We only need this for SSL (https) connections</span>
<span class="c1">#dashboard_crt: ''</span>
<span class="c1">#dashboard_key: ''</span>
<span class="c1">#dashboard_rgw_api_user_id: ceph-dashboard</span>
<span class="c1">#dashboard_rgw_api_admin_resource: ''</span>
<span class="c1">#dashboard_rgw_api_no_ssl_verify: False</span>
<span class="c1">#dashboard_frontend_vip: ''</span>
<span class="c1">#node_exporter_container_image: "docker.io/prom/node-exporter:v0.17.0"</span>
<span class="c1">#node_exporter_port: 9100</span>
<span class="c1">#grafana_admin_user: admin</span>
<span class="c1"># This variable must be set with a strong custom password when dashboard_enabled is True</span>
<span class="na">grafana_admin_password</span><span class="pi">:</span> <span class="s">password</span>
<span class="c1"># We only need this for SSL (https) connections</span>
<span class="c1">#grafana_crt: ''</span>
<span class="c1">#grafana_key: ''</span>
<span class="c1"># When using https, please fill with a hostname for which grafana_crt is valid.</span>
<span class="c1">#grafana_server_fqdn: ''</span>
<span class="c1">#grafana_container_image: "docker.io/grafana/grafana:5.4.3"</span>
<span class="c1">#grafana_container_cpu_period: 100000</span>
<span class="c1">#grafana_container_cpu_cores: 2</span>
<span class="c1"># container_memory is in GB</span>
<span class="c1">#grafana_container_memory: 4</span>
<span class="c1">#grafana_uid: 472</span>
<span class="c1">#grafana_datasource: Dashboard</span>
<span class="c1">#grafana_dashboards_path: "/etc/grafana/dashboards/ceph-dashboard"</span>
<span class="c1">#grafana_dashboard_version: master</span>
<span class="c1">#grafana_dashboard_files:</span>
<span class="c1">#  - ceph-cluster.json</span>
<span class="c1">#  - cephfs-overview.json</span>
<span class="c1">#  - host-details.json</span>
<span class="c1">#  - hosts-overview.json</span>
<span class="c1">#  - osd-device-details.json</span>
<span class="c1">#  - osds-overview.json</span>
<span class="c1">#  - pool-detail.json</span>
<span class="c1">#  - pool-overview.json</span>
<span class="c1">#  - radosgw-detail.json</span>
<span class="c1">#  - radosgw-overview.json</span>
<span class="c1">#  - rbd-overview.json</span>
<span class="c1">#grafana_plugins:</span>
<span class="c1">#  - vonage-status-panel</span>
<span class="c1">#  - grafana-piechart-panel</span>
<span class="c1">#grafana_allow_embedding: True</span>
<span class="c1">#grafana_port: 3000</span>
<span class="c1">#prometheus_container_image: "docker.io/prom/prometheus:v2.7.2"</span>
<span class="c1">#prometheus_container_cpu_period: 100000</span>
<span class="c1">#prometheus_container_cpu_cores: 2</span>
<span class="c1"># container_memory is in GB</span>
<span class="c1">#prometheus_container_memory: 4</span>
<span class="c1">#prometheus_data_dir: /var/lib/prometheus</span>
<span class="c1">#prometheus_conf_dir: /etc/prometheus</span>
<span class="c1">#prometheus_user_id: '65534'  # This is the UID used by the prom/prometheus container image</span>
<span class="c1">#prometheus_port: 9092</span>
<span class="c1">#alertmanager_container_image: "docker.io/prom/alertmanager:v0.16.2"</span>
<span class="c1">#alertmanager_container_cpu_period: 100000</span>
<span class="c1">#alertmanager_container_cpu_cores: 2</span>
<span class="c1"># container_memory is in GB</span>
<span class="c1">#alertmanager_container_memory: 4</span>
<span class="c1">#alertmanager_data_dir: /var/lib/alertmanager</span>
<span class="c1">#alertmanager_conf_dir: /etc/alertmanager</span>
<span class="c1">#alertmanager_port: 9093</span>
<span class="c1">#alertmanager_cluster_port: 9094</span>
<span class="nn">---</span>
<span class="s">略</span>
</pre></table></code></div></div><ul><li>修改 group_vars/osds.yml 中的配置。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>18: copy_admin_key: true
36: devices:
37:   - /dev/vdb
50: osd_scenario: collocated
</pre></table></code></div></div><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre><td class="rouge-code"><pre><span class="nn">---</span>
<span class="c1"># Variables here are applicable to all host groups NOT roles</span>

<span class="c1"># This sample file generated by generate_group_vars_sample.sh</span>

<span class="c1"># Dummy variable to avoid error because ansible does not recognize the</span>
<span class="c1"># file as a good configuration file when no variable in it.</span>
<span class="na">dummy</span><span class="pi">:</span>

<span class="c1">###########</span>
<span class="c1"># GENERAL #</span>
<span class="c1">###########</span>

<span class="c1"># Even though OSD nodes should not have the admin key</span>
<span class="c1"># at their disposal, some people might want to have it</span>
<span class="c1"># distributed on OSD nodes. Setting 'copy_admin_key' to 'true'</span>
<span class="c1"># will copy the admin key to the /etc/ceph/ directory</span>
<span class="na">copy_admin_key</span><span class="pi">:</span> <span class="kc">true</span>


<span class="c1">##############</span>
<span class="c1"># CEPH OPTIONS</span>
<span class="c1">##############</span>

<span class="c1"># Devices to be used as OSDs</span>
<span class="c1"># You can pre-provision disks that are not present yet.</span>
<span class="c1"># Ansible will just skip them. Newly added disk will be</span>
<span class="c1"># automatically configured during the next run.</span>
<span class="c1">#</span>


<span class="c1"># Declare devices to be used as OSDs</span>
<span class="c1"># All scenario(except 3rd) inherit from the following device declaration</span>
<span class="c1"># Note: This scenario uses the ceph-volume lvm batch method to provision OSDs</span>

<span class="c1"># 因目前使用 openstack VM 所以只有一個 disk </span>
<span class="c1"># devices: 用來儲存的裝置，可以定義多個，如果每個 node 並不相同的話，可以嘗試使用 'osd_auto_discovery'，將其設為 true。</span>

<span class="na">devices</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">/dev/vdb</span>
<span class="c1">#  - /dev/sdc</span>
<span class="c1">#  - /dev/sdd</span>
<span class="c1">#  - /dev/sde</span>

<span class="c1"># osd_scenario: OSD 的部署方式，有 collocated、non-collocated、lvm 三種選項。</span>
<span class="c1"># collocated: 將 ceph data, ceph block, ceph block.db, ceph block.wal 放在同一個裝置上。</span>
<span class="c1"># non-collocated: 會將 ceph data 跟 ceph block 放在 devices 上，並且將 ceph block.db 跟 ceph block.wal 放在額外設定的 dedicated_devices 上。</span>
<span class="c1"># lvm`: 需要設定 data, wal 跟 db 的 lv name 跟 vg group，只有 data 為必填選項</span>

<span class="na">osd_scenario</span><span class="pi">:</span> <span class="s">collocated</span>
<span class="nn">---</span>
<span class="s">略</span>
</pre></table></code></div></div><ul><li>修改 group_vars/mgrs.yml 中的配置。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>26: ceph_mgr_modules: [status]
</pre></table></code></div></div><div class="language-yml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre><span class="nn">---</span>
<span class="c1"># Variables here are applicable to all host groups NOT roles</span>

<span class="c1"># This sample file generated by generate_group_vars_sample.sh</span>

<span class="c1"># Dummy variable to avoid error because ansible does not recognize the</span>
<span class="c1"># file as a good configuration file when no variable in it.</span>
<span class="na">dummy</span><span class="pi">:</span>

<span class="c1">##########</span>
<span class="c1"># GLOBAL #</span>
<span class="c1">##########</span>
<span class="c1"># Even though MGR nodes should not have the admin key</span>
<span class="c1"># at their disposal, some people might want to have it</span>
<span class="c1"># distributed on MGR nodes. Setting 'copy_admin_key' to 'true'</span>
<span class="c1"># will copy the admin key to the /etc/ceph/ directory</span>
<span class="c1">#copy_admin_key: false</span>
<span class="c1">#mgr_secret: 'mgr_secret'</span>


<span class="c1">###########</span>
<span class="c1"># MODULES #</span>
<span class="c1">###########</span>
<span class="c1"># Ceph mgr modules to enable, to view the list of available mpdules see: http://docs.ceph.com/docs/CEPH_VERSION/mgr/</span>
<span class="c1"># and replace CEPH_VERSION with your current Ceph version, e,g: 'mimic'</span>
<span class="na">ceph_mgr_modules</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">status</span><span class="pi">]</span>
</pre></table></code></div></div><ul><li>修改 site.yml 中的配置。<li>完成上述的編輯以後，透過下面指令進行部署。</ul><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>root@ceph-ansible:~/ceph-ansible# ansible-playbook site.yml
</pre></table></code></div></div><h4 id="完成-"><span class="me-2">完成 !</span><a href="#完成-" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4><p><a href="https://miro.medium.com/max/1400/1*7_nPOonnlpmBCzo3NoXomQ.png" class="popup img-link shimmer"><img src="https://miro.medium.com/max/1400/1*7_nPOonnlpmBCzo3NoXomQ.png" alt="" loading="lazy"></a></p><p><em><a href="https://medium.com/jacky-life/ubuntu-%E9%80%8F%E9%81%8E-ansible-%E9%83%A8%E7%BD%B2-ceph-6a4af7a1f208" target="_blank">Post</a> converted from Medium by <a href="https://github.com/ZhgChgLi/ZMediumToMarkdown" target="_blank">ZMediumToMarkdown</a>.</em></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/jackycsie/">Jackycsie</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/ceph/" class="post-tag no-text-decoration" >ceph</a> <a href="/tags/ansible/" class="post-tag no-text-decoration" >ansible</a> <a href="/tags/ubuntu/" class="post-tag no-text-decoration" >ubuntu</a> <a href="/tags/filesystem/" class="post-tag no-text-decoration" >filesystem</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Ubuntu%20%E9%80%8F%E9%81%8E%20Ansible%20%E9%83%A8%E7%BD%B2%20CEPH%20-%20Medium%20To%20Jekyll%20Starter&url=https%3A%2F%2Fmedium-to-jekyll-starter.zhgchg.li%2F%2Fposts%2F6a4af7a1f208%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Ubuntu%20%E9%80%8F%E9%81%8E%20Ansible%20%E9%83%A8%E7%BD%B2%20CEPH%20-%20Medium%20To%20Jekyll%20Starter&u=https%3A%2F%2Fmedium-to-jekyll-starter.zhgchg.li%2F%2Fposts%2F6a4af7a1f208%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fmedium-to-jekyll-starter.zhgchg.li%2F%2Fposts%2F6a4af7a1f208%2F&text=Ubuntu%20%E9%80%8F%E9%81%8E%20Ansible%20%E9%83%A8%E7%BD%B2%20CEPH%20-%20Medium%20To%20Jekyll%20Starter" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/6fc300705d47/">How to Learn New Skills Effectively: Work Smarter, Not Harder</a><li class="text-truncate lh-lg"> <a href="/posts/Welcome/">ZMediumToJekyll Starter</a><li class="text-truncate lh-lg"> <a href="/posts/da095b9be519/">AWS 雲端 信義房屋 賣房爬蟲架構</a><li class="text-truncate lh-lg"> <a href="/posts/4a17936aea1a/">AWS 雲端 591 租屋爬蟲架構</a><li class="text-truncate lh-lg"> <a href="/posts/82bebda01507/">AWS EC2 中部署 LLM</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/tools/">tools</a> <a class="post-tag btn btn-outline-primary" href="/tags/leetcode/">leetcode</a> <a class="post-tag btn btn-outline-primary" href="/tags/ceph/">ceph</a> <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a> <a class="post-tag btn btn-outline-primary" href="/tags/aws/">aws</a> <a class="post-tag btn btn-outline-primary" href="/tags/gene/">gene</a> <a class="post-tag btn btn-outline-primary" href="/tags/kubernetes/">kubernetes</a> <a class="post-tag btn btn-outline-primary" href="/tags/life/">life</a> <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep-learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/ecg/">ecg</a></div></section></div><div class="toc-border-cover z-3"></div><section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4"><h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/6bbe4aeaf2cf/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1600998502" data-df="ll" > Sep 25, 2020 </time><h4 class="pt-0 my-2">透過 K8S 建立 NFS 服務</h4><div class="text-muted"><p>本文將介紹，透過 kubernetes 建立 NFS 服務， Storage class 會使用 CEPH RBD 做儲存空間。</p></div></div></a></article><article class="col"> <a href="/posts/1999f52a6fb9/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1600245736" data-df="ll" > Sep 16, 2020 </time><h4 class="pt-0 my-2">在 K8S 使用 Rook 安裝 CEPH</h4><div class="text-muted"><p>本文將介紹如何使用 Rook 將 K8S 與 CEPH 連接。</p></div></div></a></article><article class="col"> <a href="/posts/9132e0ee7018/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1594366311" data-df="ll" > Jul 10, 2020 </time><h4 class="pt-0 my-2">Deploy Ceph cache tier & erasure code</h4><div class="text-muted"><p>本篇文章主要紀錄的是如何應用 cache tier 與 erasure code 在 Cephfs 當中。</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/5416e0765d5f/" class="btn btn-outline-primary" aria-label="Older" ><p>使用 CephFS 代替 HDFS</p></a> <a href="/posts/c239929d2176/" class="btn btn-outline-primary" aria-label="Newer" ><p>MLflow: 紀錄您 Train 步驟的平台</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://twitter.com/username">your_full_name</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.2.4" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.<br/> Automatically sync posts from Medium with <a href="https://zhgchg.li/posts/en-medium-to-jekyll/" target="_blank">ZhgChg.Li</a>.</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/tools/">tools</a> <a class="post-tag btn btn-outline-primary" href="/tags/leetcode/">leetcode</a> <a class="post-tag btn btn-outline-primary" href="/tags/ceph/">ceph</a> <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a> <a class="post-tag btn btn-outline-primary" href="/tags/aws/">aws</a> <a class="post-tag btn btn-outline-primary" href="/tags/gene/">gene</a> <a class="post-tag btn btn-outline-primary" href="/tags/kubernetes/">kubernetes</a> <a class="post-tag btn btn-outline-primary" href="/tags/life/">life</a> <a class="post-tag btn btn-outline-primary" href="/tags/deep-learning/">deep-learning</a> <a class="post-tag btn btn-outline-primary" href="/tags/ecg/">ecg</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script> document.addEventListener('DOMContentLoaded', () => { SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{snippet}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); }); </script>
